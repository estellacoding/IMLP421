{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc773fd-af63-4383-9a1f-0a00b845cb2c",
   "metadata": {},
   "source": [
    "# 變數多重共線性(Multicollinearity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789af0a8-2a3f-4a56-ba08-3b035912b090",
   "metadata": {},
   "source": [
    "多重共線性是指在回歸分析時，變數間存在高度相關性從而影響回歸模型的穩定性和解釋性。\n",
    "\n",
    "- 當兩個或多個「獨立變數（預測變數/自變數）」之間存在高度相關性時，會導致難以區分這些變數對「依賴變數（目標變數/應變數）」的獨立影響。\n",
    "- 高度相關的變數會使得難以明確區分哪個變數對目標變數有較大的影響。\n",
    "- 計算變數之間的相關係數矩陣，如果兩個變數的相關係數接近1或-1，表示它們之間可能存在多重共線性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe575a4-2dcc-4c83-a267-eb9921e2114c",
   "metadata": {},
   "source": [
    "# 泛化(generalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc60d96-2a88-4a84-8cbf-4298947dfbb4",
   "metadata": {},
   "source": [
    "泛化(generalize)指ML模型「對未知資料集」的預測能力。\n",
    "- overfitting: model在training dataset表現不錯，但是在testing dataset表現卻很差。\n",
    "- underfitting: model在training dataset及testing dataset表現都很差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c840f-d9cd-4304-a84c-b7d6b31e0f92",
   "metadata": {},
   "source": [
    "# 如何解決OVERFITTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e32ee1-dede-4c97-b8a4-790dfdada2bc",
   "metadata": {},
   "source": [
    "If we have too many features the learned hypothesis may fit the training set very well (J(0)=0), but fail to generalize to new examples and predict on new examples\n",
    "\n",
    "1. 降低features的數量: 人工選擇、model selection algorithm。\n",
    "2. Regularization: 維持現有的features，但是降低部分不重要feature的影響力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7600d95c-3d05-4e14-9fd1-bb7721033965",
   "metadata": {},
   "source": [
    "# 歸一化(Normalization) vs 正則化(Regularization)  vs 標準化(Standardization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ac3b5c-2b98-4b42-b3e7-f1dfa5032e9a",
   "metadata": {},
   "source": [
    "## 歸一化(Normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc83a60-1f2e-4627-9f56-641618693f57",
   "metadata": {},
   "source": [
    "- 將數據重新縮放到特定範圍（通常是 [0, 1] 或 [-1, 1]）。\n",
    "- 防止某些特徵因數值範圍較大而對模型產生過大的影響。\n",
    "- 常用於需要計算距離的演算法，如 KNN、K-Means。\n",
    "- 常見方法: Min-Max Normalization。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4160c-e1e9-4e93-aaa2-82e9a7eaf201",
   "metadata": {},
   "source": [
    "## 標準化(Standardization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a33ea-63a7-414e-a779-87d62a5f0ad1",
   "metadata": {},
   "source": [
    "- 將數據轉換為均值為 0、標準差為 1 的正態分佈。\n",
    "- 使用需要計算距離的演算法時，如支持向量機(SVM)、K-Means等。\n",
    "- 常見方法：Standardization (z-score)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dd634b-1711-4250-9c3b-99c23532443a",
   "metadata": {},
   "source": [
    "## 正則化(Regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233883c5-285a-43c5-bedf-a0dfe67962fe",
   "metadata": {},
   "source": [
    "- 在模型的損失函數中加入懲罰項，防止過擬合。\n",
    "- 在損失函數中加入懲罰項，使得模型參數的值較小（即權重較小）。\n",
    "- 常見方法：L1 正則化(Lasso)、L2 正則化(Ridge)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a308f4-1de0-4826-a8e3-c3278cc81f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ef383-8e7f-4b8d-a9fe-d4a9391e2b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sk-env",
   "language": "python",
   "name": "sk-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
