{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自動調參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 參數使用\n",
    "\n",
    "```\n",
    "class sklearn.model_selection.GridSearchCV(estimator, param_grid, scoring=None, fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, verbose=0, pre_dispatch=‘2*n_jobs’, error_score=’raise’, return_train_score=’warn’)\n",
    "\n",
    "estimator：所使用的分類器，比如：estimator=RandomForestClassifier(min_samples_split=100, min_samples_leaf=20, max_depth=8, max_features=‘sqrt‘, random_state=10)，並且傳入除需要確定最佳的參數之外的其他參數。每個分類器都需要一個scoring參數或者score方法。\n",
    "param_grid：值為字典或列表，即需要最優化的參數的取值，param_grid =param_test1，param_test1 = {‘n_estimators‘:range(10,71,10)}\n",
    "scoring：準確評價標準，默認為None（使用estimator的誤差估計函數），這時需要使用score函數；或者如scoring=‘roc_auc‘，根據所選模型不同，評價準則不同。\n",
    "cv：交叉驗證參數，默認為None\n",
    "refit：默認為True，程序將會以交叉驗證訓練集得到的最佳參數，重新對所有可用的訓練集與測試集進行，作為最終用於性能評估的最佳模型參數。即在搜索參數結束後，用最佳參數結果再次fit一遍全部數據集。\n",
    "iid:默認True,為True時，默認為各個樣本fold概率分布一致，誤差估計為所有樣本之和，而非各個fold的平均。\n",
    "\n",
    "verbose：日誌冗長度，int：冗長度，0：不輸出訓練過程，1：偶爾輸出，>1：對每個子模型都輸出。\n",
    "\n",
    "n_jobs: 並行數，int：個數,-1：跟CPU核數一致, 1:默認值。\n",
    "\n",
    "pre_dispatch：指定總共分發的並行任務數。當n_jobs大於1時，數據將在每個運行點進行復制，這可能導致OOM，而設置pre_dispatch參數，則可以預先劃分總共的job數量，使數據最多被復制pre_dispatch次，進行預測的常用方法和屬性\n",
    "\n",
    "grid.fit()：運行網格搜索\n",
    "\n",
    "grid_scores_：給出不同參數情況下的評價結果\n",
    "\n",
    "best_params_：描述了已取得最佳結果的參數的組合\n",
    "\n",
    "best_score_：成員提供優化過程期間觀察到的最好的評分\n",
    "```\n",
    "\n",
    "## 屬性方法：\n",
    "* grid.fit( train_x, train_y )：運行網格搜索\n",
    "* grid_scores_：給出不同參數情況下的評價結果\n",
    "* best_params_：描述了已取得最佳結果的參數的組合\n",
    "* best_score_：成員提供優化過程期間觀察到的最好的評分\n",
    "\n",
    "[GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "## Progress bar for models fitting\n",
    "> conda install keras-tqdm\n",
    "\n",
    "[tqdm](https://github.com/bstriner/keras-tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV # 自動調參\n",
    "from sklearn.feature_extraction import DictVectorizer # 特徵轉換\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from keras_tqdm import TQDMCallback\n",
    "\n",
    "datapath = \"data/titanic_data.csv\"\n",
    "\n",
    "def RandomForestTest():\n",
    "    data = pd.read_csv(datapath)\n",
    "    X = data[[\"Pclass\",\"Sex\",\"Age\"]]\n",
    "    Y = data[\"Survived\"]\n",
    "\n",
    "    X[\"Age\"].fillna(X[\"Age\"].mean(),inplace=True)\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.25)\n",
    "\n",
    "    # 將特徵轉換為向量格式\n",
    "    DV = DictVectorizer(sparse=False)\n",
    "    X_train = DV.fit_transform(X_train.to_dict(orient=\"records\"))\n",
    "    X_test = DV.transform(X_test.to_dict(orient=\"records\"))\n",
    "    \n",
    "    # 實例化隨機森林分類器\n",
    "    RF = RandomForestClassifier(verbose=0)#verbose=True #verbose=0, callbacks=[TQDMCallback()]\n",
    "    \n",
    "    # 測試超參數優化\n",
    "    RF_param = {\n",
    "    \"n_estimators\": [50, 100, 200, 300], # 樹的數量\n",
    "    \"max_depth\": [5, 10, 15, 20]} # 樹的最大深度\n",
    "    \n",
    "    print(type(GridSearchCV(RF,param_grid=RF_param,cv=5)))\n",
    "    GSCV = GridSearchCV(RF,param_grid=RF_param,cv=5)\n",
    "    GSCV.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"accuracy score\",GSCV.score(X_test,y_test))\n",
    "    print(\"The best model param :\",GSCV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "accuracy score 0.8071748878923767\n",
      "The best model param : {'max_depth': 20, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "RandomForestTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.model_selection._search.GridSearchCV'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:20<00:00, 20.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.8161434977578476\n",
      "The best model param : {'max_depth': 4, 'n_estimators': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV # 自動調參\n",
    "from sklearn.feature_extraction import DictVectorizer # 特徵轉換\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from keras_tqdm import TQDMCallback\n",
    "\n",
    "datapath = \"data/titanic_data.csv\"\n",
    "\n",
    "def RandomForestTest():\n",
    "    data = pd.read_csv(datapath)\n",
    "    X = data[[\"Pclass\",\"Sex\",\"Age\"]]\n",
    "    Y = data[\"Survived\"]\n",
    "\n",
    "    # 填補缺失值，用平均值填補\n",
    "    X[\"Age\"].fillna(X[\"Age\"].mean(),inplace=True)\n",
    "\n",
    "    # 分割數據集為訓練集和測試集\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.25)\n",
    "\n",
    "    # 將特徵轉換為向量格式\n",
    "    DV = DictVectorizer(sparse=False)\n",
    "    X_train = DV.fit_transform(X_train.to_dict(orient=\"records\"))\n",
    "    X_test = DV.transform(X_test.to_dict(orient=\"records\"))\n",
    "    \n",
    "    # 實例化隨機森林分類器\n",
    "    # 設定verbose參數為0，不顯示訓練過程信息\n",
    "    RF = RandomForestClassifier(verbose=0)#verbose=True #verbose=0, callbacks=[TQDMCallback()]\n",
    "    \n",
    "    # 測試超參數優化\n",
    "    RF_param = {\n",
    "    \"n_estimators\": [25, 250, 500], # 樹的數量\n",
    "    \"max_depth\": [4, 15, 25]} # 樹的最大深度\n",
    "    \n",
    "    print(type(GridSearchCV(RF, param_grid=RF_param, cv=5)))\n",
    "    GSCV = GridSearchCV(RF, param_grid=RF_param, cv=5)\n",
    "\n",
    "    # 使用tqdm進行進度條顯示\n",
    "    for _ in tqdm(range(1), desc=\"Training Progress\"):\n",
    "        GSCV.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"accuracy score\",GSCV.score(X_test,y_test))\n",
    "    print(\"The best model param :\",GSCV.best_params_)\n",
    "\n",
    "RandomForestTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sk-env",
   "language": "python",
   "name": "sk-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
